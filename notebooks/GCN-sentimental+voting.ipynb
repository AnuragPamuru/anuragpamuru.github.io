{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GinNZkSBeFdC"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from data_loader_sen import data_loader\n",
    "from GCN_model import n_hidden_GCN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following results is when using the sentimental analysis of the tweets and the voting records of 116th congress senators as feature, and the adjacency matrix is the graph of 116th senators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XR6h2vG9L7ls"
   },
   "outputs": [],
   "source": [
    "loader = data_loader( \"../data/voting_features.csv\",\"../data/tweets.csv\", \"../data/edges.csv\")\n",
    "features, labels, A = loader.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Py0zsfIzL-VT",
    "outputId": "a4e4091b-f79f-48b5-8c4b-8c97513c9081"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train length :70, Validation length :30\n",
      "Epoch: 0\n",
      "training loss 2.1277\n",
      "Validtion: Average loss: 0.0000, Accuracy: 43.3333%\n",
      "Epoch: 1\n",
      "training loss 2.0401\n",
      "Validtion: Average loss: 0.0000, Accuracy: 43.3333%\n",
      "Epoch: 2\n",
      "training loss 1.9605\n",
      "Validtion: Average loss: 0.0000, Accuracy: 43.3333%\n",
      "Epoch: 3\n",
      "training loss 1.8869\n",
      "Validtion: Average loss: 0.0000, Accuracy: 43.3333%\n",
      "Epoch: 4\n",
      "training loss 1.8188\n",
      "Validtion: Average loss: 0.0000, Accuracy: 43.3333%\n",
      "Epoch: 5\n",
      "training loss 1.7549\n",
      "Validtion: Average loss: 0.0000, Accuracy: 43.3333%\n",
      "Epoch: 6\n",
      "training loss 1.6942\n",
      "Validtion: Average loss: 0.0000, Accuracy: 43.3333%\n",
      "Epoch: 7\n",
      "training loss 1.6363\n",
      "Validtion: Average loss: 0.0000, Accuracy: 43.3333%\n",
      "Epoch: 8\n",
      "training loss 1.5818\n",
      "Validtion: Average loss: 0.0000, Accuracy: 43.3333%\n",
      "Epoch: 9\n",
      "training loss 1.5306\n",
      "Validtion: Average loss: 0.0000, Accuracy: 43.3333%\n",
      "Epoch: 10\n",
      "training loss 1.4827\n",
      "Validtion: Average loss: 0.0000, Accuracy: 43.3333%\n",
      "Epoch: 11\n",
      "training loss 1.4377\n",
      "Validtion: Average loss: 0.0000, Accuracy: 43.3333%\n",
      "Epoch: 12\n",
      "training loss 1.3950\n",
      "Validtion: Average loss: 0.0000, Accuracy: 43.3333%\n",
      "Epoch: 13\n",
      "training loss 1.3540\n",
      "Validtion: Average loss: 0.0000, Accuracy: 46.6667%\n",
      "Epoch: 14\n",
      "training loss 1.3142\n",
      "Validtion: Average loss: 0.0000, Accuracy: 46.6667%\n",
      "Epoch: 15\n",
      "training loss 1.2760\n",
      "Validtion: Average loss: 0.0000, Accuracy: 46.6667%\n",
      "Epoch: 16\n",
      "training loss 1.2385\n",
      "Validtion: Average loss: 0.0000, Accuracy: 50.0000%\n",
      "Epoch: 17\n",
      "training loss 1.2024\n",
      "Validtion: Average loss: 0.0000, Accuracy: 53.3333%\n",
      "Epoch: 18\n",
      "training loss 1.1681\n",
      "Validtion: Average loss: 0.0000, Accuracy: 53.3333%\n",
      "Epoch: 19\n",
      "training loss 1.1351\n",
      "Validtion: Average loss: 0.0000, Accuracy: 53.3333%\n",
      "Epoch: 20\n",
      "training loss 1.1034\n",
      "Validtion: Average loss: 0.0000, Accuracy: 53.3333%\n",
      "Epoch: 21\n",
      "training loss 1.0726\n",
      "Validtion: Average loss: 0.0000, Accuracy: 56.6667%\n",
      "Epoch: 22\n",
      "training loss 1.0420\n",
      "Validtion: Average loss: 0.0000, Accuracy: 56.6667%\n",
      "Epoch: 23\n",
      "training loss 1.0121\n",
      "Validtion: Average loss: 0.0000, Accuracy: 56.6667%\n",
      "Epoch: 24\n",
      "training loss 0.9830\n",
      "Validtion: Average loss: 0.0000, Accuracy: 56.6667%\n",
      "Epoch: 25\n",
      "training loss 0.9548\n",
      "Validtion: Average loss: 0.0000, Accuracy: 60.0000%\n",
      "Epoch: 26\n",
      "training loss 0.9275\n",
      "Validtion: Average loss: 0.0000, Accuracy: 60.0000%\n",
      "Epoch: 27\n",
      "training loss 0.9012\n",
      "Validtion: Average loss: 0.0000, Accuracy: 60.0000%\n",
      "Epoch: 28\n",
      "training loss 0.8759\n",
      "Validtion: Average loss: 0.0000, Accuracy: 60.0000%\n",
      "Epoch: 29\n",
      "training loss 0.8515\n",
      "Validtion: Average loss: 0.0000, Accuracy: 60.0000%\n",
      "Epoch: 30\n",
      "training loss 0.8279\n",
      "Validtion: Average loss: 0.0000, Accuracy: 60.0000%\n",
      "Epoch: 31\n",
      "training loss 0.8051\n",
      "Validtion: Average loss: 0.0000, Accuracy: 63.3333%\n",
      "Epoch: 32\n",
      "training loss 0.7829\n",
      "Validtion: Average loss: 0.0000, Accuracy: 63.3333%\n",
      "Epoch: 33\n",
      "training loss 0.7613\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 34\n",
      "training loss 0.7403\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 35\n",
      "training loss 0.7197\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 36\n",
      "training loss 0.6996\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 37\n",
      "training loss 0.6800\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 38\n",
      "training loss 0.6610\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 39\n",
      "training loss 0.6427\n",
      "Validtion: Average loss: 0.0000, Accuracy: 66.6667%\n",
      "Epoch: 40\n",
      "training loss 0.6250\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 41\n",
      "training loss 0.6080\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 42\n",
      "training loss 0.5918\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 43\n",
      "training loss 0.5763\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 44\n",
      "training loss 0.5617\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 45\n",
      "training loss 0.5477\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 46\n",
      "training loss 0.5344\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 47\n",
      "training loss 0.5216\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 48\n",
      "training loss 0.5093\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 49\n",
      "training loss 0.4975\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 50\n",
      "training loss 0.4861\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 51\n",
      "training loss 0.4752\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 52\n",
      "training loss 0.4646\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 53\n",
      "training loss 0.4544\n",
      "Validtion: Average loss: 0.0000, Accuracy: 70.0000%\n",
      "Epoch: 54\n",
      "training loss 0.4445\n",
      "Validtion: Average loss: 0.0000, Accuracy: 73.3333%\n",
      "Epoch: 55\n",
      "training loss 0.4350\n",
      "Validtion: Average loss: 0.0000, Accuracy: 73.3333%\n",
      "Epoch: 56\n",
      "training loss 0.4259\n",
      "Validtion: Average loss: 0.0000, Accuracy: 73.3333%\n",
      "Epoch: 57\n",
      "training loss 0.4171\n",
      "Validtion: Average loss: 0.0000, Accuracy: 73.3333%\n",
      "Epoch: 58\n",
      "training loss 0.4087\n",
      "Validtion: Average loss: 0.0000, Accuracy: 73.3333%\n",
      "Epoch: 59\n",
      "training loss 0.4005\n",
      "Validtion: Average loss: 0.0000, Accuracy: 73.3333%\n",
      "Epoch: 60\n",
      "training loss 0.3926\n",
      "Validtion: Average loss: 0.0000, Accuracy: 73.3333%\n",
      "Epoch: 61\n",
      "training loss 0.3849\n",
      "Validtion: Average loss: 0.0000, Accuracy: 73.3333%\n",
      "Epoch: 62\n",
      "training loss 0.3774\n",
      "Validtion: Average loss: 0.0000, Accuracy: 73.3333%\n",
      "Epoch: 63\n",
      "training loss 0.3702\n",
      "Validtion: Average loss: 0.0000, Accuracy: 73.3333%\n",
      "Epoch: 64\n",
      "training loss 0.3631\n",
      "Validtion: Average loss: 0.0000, Accuracy: 73.3333%\n",
      "Epoch: 65\n",
      "training loss 0.3562\n",
      "Validtion: Average loss: 0.0000, Accuracy: 73.3333%\n",
      "Epoch: 66\n",
      "training loss 0.3495\n",
      "Validtion: Average loss: 0.0000, Accuracy: 73.3333%\n",
      "Epoch: 67\n",
      "training loss 0.3429\n",
      "Validtion: Average loss: 0.0000, Accuracy: 73.3333%\n",
      "Epoch: 68\n",
      "training loss 0.3365\n",
      "Validtion: Average loss: 0.0000, Accuracy: 73.3333%\n",
      "Epoch: 69\n",
      "training loss 0.3303\n",
      "Validtion: Average loss: 0.0000, Accuracy: 73.3333%\n",
      "Epoch: 70\n",
      "training loss 0.3242\n",
      "Validtion: Average loss: 0.0000, Accuracy: 76.6667%\n",
      "Epoch: 71\n",
      "training loss 0.3183\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 72\n",
      "training loss 0.3125\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 73\n",
      "training loss 0.3068\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 74\n",
      "training loss 0.3013\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 75\n",
      "training loss 0.2959\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 76\n",
      "training loss 0.2906\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 77\n",
      "training loss 0.2855\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 78\n",
      "training loss 0.2804\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 79\n",
      "training loss 0.2755\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 80\n",
      "training loss 0.2707\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 81\n",
      "training loss 0.2660\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 82\n",
      "training loss 0.2614\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 83\n",
      "training loss 0.2568\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 84\n",
      "training loss 0.2524\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 85\n",
      "training loss 0.2480\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 86\n",
      "training loss 0.2438\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 87\n",
      "training loss 0.2396\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 88\n",
      "training loss 0.2354\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 89\n",
      "training loss 0.2314\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 90\n",
      "training loss 0.2275\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 91\n",
      "training loss 0.2236\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 92\n",
      "training loss 0.2198\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 93\n",
      "training loss 0.2161\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 94\n",
      "training loss 0.2125\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 95\n",
      "training loss 0.2090\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 96\n",
      "training loss 0.2055\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 97\n",
      "training loss 0.2021\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 98\n",
      "training loss 0.1988\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 99\n",
      "training loss 0.1955\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 100\n",
      "training loss 0.1924\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 101\n",
      "training loss 0.1893\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 102\n",
      "training loss 0.1863\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 103\n",
      "training loss 0.1833\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 104\n",
      "training loss 0.1805\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 105\n",
      "training loss 0.1777\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 106\n",
      "training loss 0.1750\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 107\n",
      "training loss 0.1724\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 108\n",
      "training loss 0.1699\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 109\n",
      "training loss 0.1674\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 110\n",
      "training loss 0.1650\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 111\n",
      "training loss 0.1627\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 112\n",
      "training loss 0.1605\n",
      "Validtion: Average loss: 0.0000, Accuracy: 80.0000%\n",
      "Epoch: 113\n",
      "training loss 0.1583\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 114\n",
      "training loss 0.1562\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 115\n",
      "training loss 0.1541\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 116\n",
      "training loss 0.1522\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 117\n",
      "training loss 0.1502\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 118\n",
      "training loss 0.1484\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 119\n",
      "training loss 0.1466\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 120\n",
      "training loss 0.1449\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 121\n",
      "training loss 0.1432\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 122\n",
      "training loss 0.1416\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 123\n",
      "training loss 0.1400\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 124\n",
      "training loss 0.1384\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 125\n",
      "training loss 0.1369\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 126\n",
      "training loss 0.1354\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 127\n",
      "training loss 0.1340\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 128\n",
      "training loss 0.1326\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 129\n",
      "training loss 0.1313\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 130\n",
      "training loss 0.1299\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 131\n",
      "training loss 0.1286\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 132\n",
      "training loss 0.1273\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 133\n",
      "training loss 0.1261\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 134\n",
      "training loss 0.1249\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 135\n",
      "training loss 0.1237\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 136\n",
      "training loss 0.1225\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 137\n",
      "training loss 0.1214\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 138\n",
      "training loss 0.1202\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 139\n",
      "training loss 0.1191\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 140\n",
      "training loss 0.1181\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 141\n",
      "training loss 0.1170\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 142\n",
      "training loss 0.1160\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 143\n",
      "training loss 0.1149\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 144\n",
      "training loss 0.1140\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 145\n",
      "training loss 0.1130\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 146\n",
      "training loss 0.1120\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 147\n",
      "training loss 0.1111\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 148\n",
      "training loss 0.1101\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 149\n",
      "training loss 0.1092\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 150\n",
      "training loss 0.1083\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 151\n",
      "training loss 0.1074\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 152\n",
      "training loss 0.1066\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 153\n",
      "training loss 0.1057\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 154\n",
      "training loss 0.1049\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 155\n",
      "training loss 0.1040\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 156\n",
      "training loss 0.1032\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 157\n",
      "training loss 0.1024\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 158\n",
      "training loss 0.1016\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 159\n",
      "training loss 0.1009\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 160\n",
      "training loss 0.1001\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 161\n",
      "training loss 0.0994\n",
      "Validtion: Average loss: 0.0000, Accuracy: 83.3333%\n",
      "Epoch: 162\n",
      "training loss 0.0986\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 163\n",
      "training loss 0.0979\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 164\n",
      "training loss 0.0972\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 165\n",
      "training loss 0.0965\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 166\n",
      "training loss 0.0958\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 167\n",
      "training loss 0.0952\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 168\n",
      "training loss 0.0945\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 169\n",
      "training loss 0.0938\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 170\n",
      "training loss 0.0932\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 171\n",
      "training loss 0.0926\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 172\n",
      "training loss 0.0919\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 173\n",
      "training loss 0.0913\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 174\n",
      "training loss 0.0907\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 175\n",
      "training loss 0.0901\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 176\n",
      "training loss 0.0896\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 177\n",
      "training loss 0.0890\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 178\n",
      "training loss 0.0884\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 179\n",
      "training loss 0.0879\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 180\n",
      "training loss 0.0873\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 181\n",
      "training loss 0.0868\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 182\n",
      "training loss 0.0862\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 183\n",
      "training loss 0.0857\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 184\n",
      "training loss 0.0852\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 185\n",
      "training loss 0.0847\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 186\n",
      "training loss 0.0842\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 187\n",
      "training loss 0.0837\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 188\n",
      "training loss 0.0832\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 189\n",
      "training loss 0.0827\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 190\n",
      "training loss 0.0822\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 191\n",
      "training loss 0.0818\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 192\n",
      "training loss 0.0813\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 193\n",
      "training loss 0.0809\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 194\n",
      "training loss 0.0804\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 195\n",
      "training loss 0.0800\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 196\n",
      "training loss 0.0795\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 197\n",
      "training loss 0.0791\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 198\n",
      "training loss 0.0787\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 199\n",
      "training loss 0.0783\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 200\n",
      "training loss 0.0779\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 201\n",
      "training loss 0.0774\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 202\n",
      "training loss 0.0770\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 203\n",
      "training loss 0.0766\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 204\n",
      "training loss 0.0763\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 205\n",
      "training loss 0.0759\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 206\n",
      "training loss 0.0755\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 207\n",
      "training loss 0.0751\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 208\n",
      "training loss 0.0747\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 209\n",
      "training loss 0.0744\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 210\n",
      "training loss 0.0740\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 211\n",
      "training loss 0.0736\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 212\n",
      "training loss 0.0733\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 213\n",
      "training loss 0.0729\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 214\n",
      "training loss 0.0726\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 215\n",
      "training loss 0.0722\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 216\n",
      "training loss 0.0719\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 217\n",
      "training loss 0.0715\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 218\n",
      "training loss 0.0712\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 219\n",
      "training loss 0.0708\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 220\n",
      "training loss 0.0705\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 221\n",
      "training loss 0.0702\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 222\n",
      "training loss 0.0699\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 223\n",
      "training loss 0.0695\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 224\n",
      "training loss 0.0692\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 225\n",
      "training loss 0.0689\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 226\n",
      "training loss 0.0686\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 227\n",
      "training loss 0.0683\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 228\n",
      "training loss 0.0680\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 229\n",
      "training loss 0.0677\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 230\n",
      "training loss 0.0674\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 231\n",
      "training loss 0.0671\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 232\n",
      "training loss 0.0668\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 233\n",
      "training loss 0.0665\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 234\n",
      "training loss 0.0662\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 235\n",
      "training loss 0.0659\n",
      "Validtion: Average loss: 0.0000, Accuracy: 86.6667%\n",
      "Epoch: 236\n",
      "training loss 0.0656\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 237\n",
      "training loss 0.0654\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 238\n",
      "training loss 0.0651\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 239\n",
      "training loss 0.0648\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 240\n",
      "training loss 0.0645\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 241\n",
      "training loss 0.0643\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 242\n",
      "training loss 0.0640\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 243\n",
      "training loss 0.0638\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 244\n",
      "training loss 0.0635\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 245\n",
      "training loss 0.0632\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 246\n",
      "training loss 0.0630\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 247\n",
      "training loss 0.0627\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 248\n",
      "training loss 0.0625\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 249\n",
      "training loss 0.0622\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 250\n",
      "training loss 0.0620\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 251\n",
      "training loss 0.0617\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 252\n",
      "training loss 0.0615\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 253\n",
      "training loss 0.0612\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 254\n",
      "training loss 0.0610\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 255\n",
      "training loss 0.0608\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 256\n",
      "training loss 0.0605\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 257\n",
      "training loss 0.0603\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 258\n",
      "training loss 0.0601\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 259\n",
      "training loss 0.0598\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 260\n",
      "training loss 0.0596\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 261\n",
      "training loss 0.0594\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 262\n",
      "training loss 0.0592\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 263\n",
      "training loss 0.0590\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 264\n",
      "training loss 0.0587\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 265\n",
      "training loss 0.0585\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 266\n",
      "training loss 0.0583\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 267\n",
      "training loss 0.0581\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 268\n",
      "training loss 0.0579\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 269\n",
      "training loss 0.0576\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 270\n",
      "training loss 0.0574\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 271\n",
      "training loss 0.0572\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 272\n",
      "training loss 0.0570\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 273\n",
      "training loss 0.0568\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 274\n",
      "training loss 0.0566\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 275\n",
      "training loss 0.0564\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 276\n",
      "training loss 0.0562\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 277\n",
      "training loss 0.0560\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 278\n",
      "training loss 0.0558\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 279\n",
      "training loss 0.0556\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 280\n",
      "training loss 0.0554\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 281\n",
      "training loss 0.0552\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 282\n",
      "training loss 0.0550\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 283\n",
      "training loss 0.0548\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 284\n",
      "training loss 0.0547\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 285\n",
      "training loss 0.0545\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 286\n",
      "training loss 0.0543\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 287\n",
      "training loss 0.0541\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 288\n",
      "training loss 0.0539\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 289\n",
      "training loss 0.0537\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 290\n",
      "training loss 0.0535\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 291\n",
      "training loss 0.0534\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 292\n",
      "training loss 0.0532\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 293\n",
      "training loss 0.0530\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 294\n",
      "training loss 0.0528\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 295\n",
      "training loss 0.0527\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 296\n",
      "training loss 0.0525\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 297\n",
      "training loss 0.0523\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 298\n",
      "training loss 0.0521\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 299\n",
      "training loss 0.0520\n",
      "Validtion: Average loss: 0.0000, Accuracy: 90.0000%\n",
      "Epoch: 300\n",
      "training loss 0.0518\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 301\n",
      "training loss 0.0516\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 302\n",
      "training loss 0.0515\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 303\n",
      "training loss 0.0513\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 304\n",
      "training loss 0.0511\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 305\n",
      "training loss 0.0510\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 306\n",
      "training loss 0.0508\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 307\n",
      "training loss 0.0506\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 308\n",
      "training loss 0.0505\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 309\n",
      "training loss 0.0503\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 310\n",
      "training loss 0.0502\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 311\n",
      "training loss 0.0500\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 312\n",
      "training loss 0.0499\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 313\n",
      "training loss 0.0497\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 314\n",
      "training loss 0.0496\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 315\n",
      "training loss 0.0494\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 316\n",
      "training loss 0.0492\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 317\n",
      "training loss 0.0491\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 318\n",
      "training loss 0.0489\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 319\n",
      "training loss 0.0488\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 320\n",
      "training loss 0.0487\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 321\n",
      "training loss 0.0485\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 322\n",
      "training loss 0.0484\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 323\n",
      "training loss 0.0482\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 324\n",
      "training loss 0.0481\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 325\n",
      "training loss 0.0479\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 326\n",
      "training loss 0.0478\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 327\n",
      "training loss 0.0477\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 328\n",
      "training loss 0.0475\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 329\n",
      "training loss 0.0474\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 330\n",
      "training loss 0.0472\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 331\n",
      "training loss 0.0471\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 332\n",
      "training loss 0.0470\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 333\n",
      "training loss 0.0468\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 334\n",
      "training loss 0.0467\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 335\n",
      "training loss 0.0466\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 336\n",
      "training loss 0.0464\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 337\n",
      "training loss 0.0463\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 338\n",
      "training loss 0.0462\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 339\n",
      "training loss 0.0461\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 340\n",
      "training loss 0.0459\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 341\n",
      "training loss 0.0458\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 342\n",
      "training loss 0.0457\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 343\n",
      "training loss 0.0456\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 344\n",
      "training loss 0.0454\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 345\n",
      "training loss 0.0453\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 346\n",
      "training loss 0.0452\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 347\n",
      "training loss 0.0451\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 348\n",
      "training loss 0.0449\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 349\n",
      "training loss 0.0448\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 350\n",
      "training loss 0.0447\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 351\n",
      "training loss 0.0446\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 352\n",
      "training loss 0.0445\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 353\n",
      "training loss 0.0443\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 354\n",
      "training loss 0.0442\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 355\n",
      "training loss 0.0441\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 356\n",
      "training loss 0.0440\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 357\n",
      "training loss 0.0439\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 358\n",
      "training loss 0.0438\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 359\n",
      "training loss 0.0436\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 360\n",
      "training loss 0.0435\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 361\n",
      "training loss 0.0434\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 362\n",
      "training loss 0.0433\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 363\n",
      "training loss 0.0432\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 364\n",
      "training loss 0.0431\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 365\n",
      "training loss 0.0430\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 366\n",
      "training loss 0.0429\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 367\n",
      "training loss 0.0427\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 368\n",
      "training loss 0.0426\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 369\n",
      "training loss 0.0425\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 370\n",
      "training loss 0.0424\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 371\n",
      "training loss 0.0423\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 372\n",
      "training loss 0.0422\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 373\n",
      "training loss 0.0421\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 374\n",
      "training loss 0.0420\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 375\n",
      "training loss 0.0419\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 376\n",
      "training loss 0.0418\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 377\n",
      "training loss 0.0417\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 378\n",
      "training loss 0.0416\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 379\n",
      "training loss 0.0415\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 380\n",
      "training loss 0.0414\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 381\n",
      "training loss 0.0413\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 382\n",
      "training loss 0.0412\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 383\n",
      "training loss 0.0411\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 384\n",
      "training loss 0.0410\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 385\n",
      "training loss 0.0409\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 386\n",
      "training loss 0.0408\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 387\n",
      "training loss 0.0407\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 388\n",
      "training loss 0.0406\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 389\n",
      "training loss 0.0405\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 390\n",
      "training loss 0.0404\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 391\n",
      "training loss 0.0403\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 392\n",
      "training loss 0.0402\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 393\n",
      "training loss 0.0401\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 394\n",
      "training loss 0.0400\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 395\n",
      "training loss 0.0399\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 396\n",
      "training loss 0.0398\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 397\n",
      "training loss 0.0397\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 398\n",
      "training loss 0.0396\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n",
      "Epoch: 399\n",
      "training loss 0.0395\n",
      "Validtion: Average loss: 0.0000, Accuracy: 93.3333%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': [43.333333333333336,\n",
       "  43.333333333333336,\n",
       "  43.333333333333336,\n",
       "  43.333333333333336,\n",
       "  43.333333333333336,\n",
       "  43.333333333333336,\n",
       "  43.333333333333336,\n",
       "  43.333333333333336,\n",
       "  43.333333333333336,\n",
       "  43.333333333333336,\n",
       "  43.333333333333336,\n",
       "  43.333333333333336,\n",
       "  43.333333333333336,\n",
       "  46.666666666666664,\n",
       "  46.666666666666664,\n",
       "  46.666666666666664,\n",
       "  50.0,\n",
       "  53.333333333333336,\n",
       "  53.333333333333336,\n",
       "  53.333333333333336,\n",
       "  53.333333333333336,\n",
       "  56.666666666666664,\n",
       "  56.666666666666664,\n",
       "  56.666666666666664,\n",
       "  56.666666666666664,\n",
       "  60.0,\n",
       "  60.0,\n",
       "  60.0,\n",
       "  60.0,\n",
       "  60.0,\n",
       "  60.0,\n",
       "  63.333333333333336,\n",
       "  63.333333333333336,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  66.66666666666667,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  73.33333333333333,\n",
       "  73.33333333333333,\n",
       "  73.33333333333333,\n",
       "  73.33333333333333,\n",
       "  73.33333333333333,\n",
       "  73.33333333333333,\n",
       "  73.33333333333333,\n",
       "  73.33333333333333,\n",
       "  73.33333333333333,\n",
       "  73.33333333333333,\n",
       "  73.33333333333333,\n",
       "  73.33333333333333,\n",
       "  73.33333333333333,\n",
       "  73.33333333333333,\n",
       "  73.33333333333333,\n",
       "  73.33333333333333,\n",
       "  76.66666666666667,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  80.0,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  83.33333333333333,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  86.66666666666667,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333,\n",
       "  93.33333333333333]}"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = n_hidden_GCN(A, features, labels, hidden_neurons=200, F = 1079, val_size=0.3)\n",
    "model.train_epoch(epochs=400, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9cpRMDmLfAh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GCN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
